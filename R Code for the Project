library(tidyverse)
library(caret)
library(readxl)
library(MASS)
library(pROC)
library(mlbench)
library(corrplot)
library(extrafont)
library(mlr)
library(parallelMap)
library(parallel)
library(rpart.plot)
library(xgboost)

# create system date.
dateVariable <- Sys.Date()
dateVariable <-  format(dateVariable, format = "%B %d, %Y")

# custom theme
theme_jacob <- function () { 
  theme_minimal(base_size=9, base_family="Gill Sans MT") %+replace% 
    theme(
      panel.grid.minor = element_blank(),
      plot.background = element_rect(fill = 'floralwhite', color = 'floralwhite')
    )
}

# Loading in Historical Data ----
nba <- read_xlsx('historicalnbadata.xlsx')
nba

head(nba)
str(nba)

nba$allNBA <- as.factor(nba$allNBA)
nba$allStar <- as.factor(nba$allStar)

nba1 <- nba %>%
  group_by(allNBA) %>%
  mutate(meanPPG = mean(PPG))
nba1

# keeping only these dimensions ----
nbaKNN <- nba %>%
  dplyr::select(teamWins, PPG, TRB, AST, STL, BLK, WS, allStar, allNBA)
str(nbaKNN)

nbacorr <- nba %>%
  dplyr::select(teamWins, overallSeed, PPG, TRB, AST, STL, BLK, WS, VORP)

nbacorr2 <- nba %>%
  dplyr::select(teamWins, overallSeed, PPG, TRB, AST, STL, BLK, WS, VORP, BPM)
# our all star break test data that we're going to use the final model on.
nbaAllStarTest <- read_csv('2020allstarbreakdata.csv')

str(nbaAllStarTest3)
nbaAllStarTest3 <- nbaAllStarTest %>%
  dplyr::select(teamWins, PPG, TRB, AST, STL, BLK, WS, allStar, allNBA)
nbaAllStarTest3$allStar <- as.factor(nbaAllStarTest3$allStar)
nbaAllStarTest3$allNBA <- as.factor(nbaAllStarTest3$allNBA)

str(nbaAllStarTest4)
nbaAllStarTest4$allStar <- as.factor(nbaAllStarTest4$allStar)

nbaAllStarTest4 <- nbaAllStarTest3 %>%
  dplyr::select(teamWins, PPG, TRB, AST, STL, BLK, WS, allStar)
# Scatterplots ----
# PPG
ggplot(nba, aes(PPG, teamWins, color = allNBA)) +
  geom_point() +
  scale_color_manual(name = 'All NBA', values = c('blue', 'red'), labels = c('No', 'Yes')) +
  scale_x_continuous(breaks = c(10, 15, 20, 25, 30, 35)) +
  scale_y_continuous(breaks = c(20, 30, 40, 50, 60, 70)) +
  labs(title = 'Historical Regular Season Team Wins vs Player PPG', caption = 'Data via basketball-reference.com',
       y = 'Team Wins', x = 'Points per Game') +
  theme_jacob() +
  theme(plot.title = element_text(hjust = 0.5), legend.position = 'top')

# VORP
ggplot(nba, aes(VORP, teamWins, color = allNBA)) +
  geom_point() +
  scale_color_manual(name = 'All NBA', values = c('blue', 'red'), labels = c('No', 'Yes')) +
  scale_x_continuous(breaks = c(0, 2, 4, 6, 8, 10, 12)) +
  scale_y_continuous(breaks = c(20, 30, 40, 50, 60, 70)) +
  labs(title = 'Historical Regular Season Team Wins vs VORP', caption = 'Data via basketball-reference.com',
       y = 'Team Wins') +
  theme_jacob() +
  theme(plot.title = element_text(hjust = 0.5), legend.position = 'top')

# Win Shares
ggplot(nba, aes(PPG, WS, color = allNBA)) +
  geom_point() +
  scale_color_manual(name = 'All NBA', values = c('blue', 'red'), labels = c('No', 'Yes')) +
  scale_x_continuous(breaks = c(10, 15, 20, 25, 30, 35)) +
  scale_y_continuous(breaks = c(0, 5, 10, 15, 20)) +
  labs(title = 'Historical Regular Season Win Shares vs PPG', caption = 'Data via basketball-reference.com',
       y = 'Win Shares', x = 'Points per Game') +
  theme_jacob() +
  theme(plot.title = element_text(hjust = 0.5), legend.position = 'top')

# VORP vs Win Shares - should only include 1 of these in the model to avoid multicolinearity.
ggplot(nba, aes(VORP, WS, color = allNBA)) +
  geom_point() +
  scale_color_manual(name = 'All NBA', values = c('blue', 'red'), labels = c('No', 'Yes')) +
  scale_x_continuous(breaks = c(0, 2, 4, 6, 8, 10, 12)) +
  scale_y_continuous(breaks = c(0, 5, 10, 15, 20)) +
  labs(title = 'Historical Regular Season Win Shares vs VORP', caption = 'Data via basketball-reference.com',
       y = 'Win Shares') +
  theme_jacob() +
  theme(plot.title = element_text(hjust = 0.5), legend.position = 'top')

# BPM vs Team Wins
ggplot(nba, aes(BPM, teamWins, color = allNBA)) +
  geom_point() +
  scale_color_manual(name = 'All NBA', values = c('blue', 'red'), labels = c('No', 'Yes')) +
  scale_x_continuous(breaks = c(-4, -2, 0, 2, 4, 6, 8, 10, 12, 14, 16)) +
  scale_y_continuous(breaks = c(20, 30, 40, 50, 60, 70)) +
  labs(title = 'Historical Regular Season Team Wins vs Player BPM', caption = 'Data via basketball-reference.com',
       y = 'Team Wins', x = 'BPM') +
  theme_jacob() +
  theme(plot.title = element_text(hjust = 0.5), legend.position = 'top')

# Team Wins vs Overall Seed - should only include 1 of these in the model to avoid multicolinearity.
ggplot(nba, aes(overallSeed, teamWins, color = allNBA)) +
  geom_point() +
  scale_color_manual(name = 'All NBA', values = c('blue', 'red'), labels = c('No', 'Yes')) +
  labs(title = 'Historical Regular Season Team Wins vs Player BPM', caption = 'Data via basketball-reference.com',
       y = 'Team Wins', x = 'Overall Seed') +
  theme_jacob() +
  theme(plot.title = element_text(hjust = 0.5), legend.position = 'top')


# Histograms ----
# PPG
ggplot(nba, aes(x = PPG, fill = allNBA)) +
  geom_histogram(alpha=0.5, position="stack") + 
  scale_fill_manual(name = 'All NBA', values = c('blue', 'red'), labels = c('No', 'Yes')) +
  labs(title = 'PPG Histogram', caption = 'Data via basketball-reference.com',
       x = 'Points per Game') +
  theme_jacob() +
  theme(plot.title = element_text(hjust = 0.5), legend.position = 'top')

# VORP
ggplot(nba, aes(x = VORP, fill = allNBA)) +
  geom_histogram(alpha=0.5, position="stack") + 
  scale_fill_manual(name = 'All NBA', values = c('blue', 'red'), labels = c('No', 'Yes')) +
  scale_x_continuous(breaks = c(0, 2, 4, 6, 8, 10, 12)) +
  labs(title = 'VORP Histogram', caption = 'Data via basketball-reference.com') +
  theme_jacob() +
  theme(plot.title = element_text(hjust = 0.5), legend.position = 'top')


# Win Shares
ggplot(nba, aes(x = WS, fill = allNBA)) +
  geom_histogram(alpha=0.5, position="stack") + 
  scale_fill_manual(name = 'All NBA', values = c('blue', 'red'), labels = c('No', 'Yes')) +
  scale_x_continuous(breaks = c(0, 5, 10, 15, 20)) +
  labs(title = 'Win Shares Histogram', caption = 'Data via basketball-reference.com',
       x = 'Win Shares') +
  theme_jacob() +
  theme(plot.title = element_text(hjust = 0.5), legend.position = 'top')


# Team Wins 
ggplot(nba, aes(x = teamWins, fill = allNBA)) +
  geom_histogram(alpha=0.5, position="stack") + 
  scale_fill_manual(name = 'All NBA', values = c('blue', 'red'), labels = c('No', 'Yes')) +
  scale_x_continuous(breaks = c(20, 30, 40, 50, 60, 70)) +
  labs(title = 'Team Wins Histogram', caption = 'Data via basketball-reference.com',
       x = 'Team Wins') +
  theme_jacob() +
  theme(plot.title = element_text(hjust = 0.5), legend.position = 'top')


# BPM
ggplot(nba, aes(x = BPM, fill = allNBA)) +
  geom_histogram(alpha=0.5, position="stack") + 
  scale_fill_manual(name = 'All NBA', values = c('blue', 'red'), labels = c('No', 'Yes')) +
  scale_x_continuous(breaks = c(-4, -2, 0, 2, 4, 6, 8, 10, 12, 14)) +
  labs(title = 'BPM Histogram', caption = 'Data via basketball-reference.com',
       x = 'BPM') +
  theme_jacob() +
  theme(plot.title = element_text(hjust = 0.5), legend.position = 'top')

# correlations ----
cr1 <- as.matrix(nbacorr)
corrplotreal <- cor(cr1)
corrplot(corrplotreal, method = 'circle')

cr2 <- as.matrix(nbacorr2)
corrplotreal2 <- cor(cr2)
corrplot(corrplotreal2, method = 'circle')

# Data Partition ----
set.seed(1234)
ind <- sample(2, nrow(nbaKNN), replace = T, prob = c(0.7, 0.3))
training <- nbaKNN[ind == 1,]
test <- nbaKNN[ind == 2,]

# KNN in Caret ----
# changing 0 and 1 for values of all-nba and allstar to 'No' and 'Yes' to avoid getting an error when executing
levels(nbaKNN$allNBA) <- c('No', 'Yes')
levels(test$allNBA) <- c('No', 'Yes')
levels(training$allNBA) <- c('No', 'Yes')

trControl1 <- trainControl(method = 'repeatedcv',
                           number = 10,
                           repeats = 3,
                           classProbs = TRUE,
                           summaryFunction = twoClassSummary)
set.seed(222)
fit1 <- train(allNBA ~ .,
              data = nbaKNN,
              method = 'knn',
              tuneLength = 20,
              trControl = trControl1,
              preProc = c('center', 'scale'),
              metric = 'ROC',
              tuneGrid = expand.grid(k = 1:60))

# Model Performance ----
fit1

# ROC Curve
plot(fit1)
ggplot(fit1) + theme_jacob()

# Confusion Matrix with the predicted vs actual values
pred1 <- predict(fit1, newdata = test)
pred1
cm <- confusionMatrix(pred1, test$allNBA) #85.4% accuracy
confusionMatrix(pred1, test$allNBA) #85.52% accuracy

# confusion matrix table creation code ----
# found from https://stackoverflow.com/questions/23891140/r-how-to-visualize-confusion-matrix-using-the-caret-package
draw_confusion_matrix <- function(cm) {
  
  total <- sum(cm$table)
  res <- as.numeric(cm$table)
  
  # Generate color gradients. Palettes come from RColorBrewer.
  greenPalette <- c("#F7FCF5","#E5F5E0","#C7E9C0","#A1D99B","#74C476","#41AB5D","#238B45","#006D2C","#00441B")
  redPalette <- c("#FFF5F0","#FEE0D2","#FCBBA1","#FC9272","#FB6A4A","#EF3B2C","#CB181D","#A50F15","#67000D")
  getColor <- function (greenOrRed = "green", amount = 0) {
    if (amount == 0)
      return("#FFFFFF")
    palette <- greenPalette
    if (greenOrRed == "red")
      palette <- redPalette
    colorRampPalette(palette)(100)[10 + ceiling(90 * amount / total)]
  }
  
  # set the basic layout
  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('Confusion Matrix with KNN', cex.main=2)
  
  # create the matrix 
  classes = colnames(cm$table)
  rect(150, 430, 240, 370, col=getColor("green", res[1]))
  text(195, 435, classes[1], cex=1.2)
  rect(250, 430, 340, 370, col=getColor("red", res[3]))
  text(295, 435, classes[2], cex=1.2)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
  text(245, 450, 'Actual', cex=1.3, font=2)
  rect(150, 305, 240, 365, col=getColor("red", res[2]))
  rect(250, 305, 340, 365, col=getColor("green", res[4]))
  text(140, 400, classes[1], cex=1.2, srt=90)
  text(140, 335, classes[2], cex=1.2, srt=90)
  
  # add in the cm results
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')
  
  # add in the specifics 
  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
  text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
  text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
  text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
  text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
  text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
  text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)
  
  # add in the accuracy information 
  text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
  text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
  text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}

draw_confusion_matrix(cm)

# Predicting All-NBA teams using pre allstar break data for the 2018-2019 season
pred2 <- predict(fit1, newdata = nbaAllStarTest3, type = 'prob')
pred2

players <- nbaAllStarTest$Player
players <- as.data.frame(players)

players$probability <- pred2$Yes
players <- players %>%
  arrange(desc(probability))
players

write_csv(players, '2020All-NBA Predictions.csv')

# Suppoer Vector Machines in mlr ---- 
# step 1 create task (specify data and dependent variable) and learner (what model building tool are you going to use)
spamTask <- makeClassifTask(data = nbaKNN, target = "allNBA")
svm <- makeLearner("classif.svm")

# step 2 hyperparameters
getParamSet("classif.svm")
getParamSet("classif.svm")$pars$kernel$values

kernels <- c("polynomial", "radial", "sigmoid")
svmParamSpace <- makeParamSet(
  makeDiscreteParam("kernel", values = kernels),
  makeIntegerParam("degree", lower = 1, upper = 3),
  makeNumericParam("cost", lower = 0.1, upper = 10),
  makeNumericParam("gamma", lower = 0.1, 10))

randSearch <- makeTuneControlRandom(maxit = 20) # random search 20 times.
cvForTuning <- makeResampleDesc("Holdout", split = 2/3) # cross validation procedure.

# step 3 stating multisearch - multithreading using all cores of our cpu to speed this process up.  
parallelStartSocket(cpus = detectCores())
tunedSvmPars <- tuneParams("classif.svm", task = spamTask,
                           resampling = cvForTuning,
                           par.set = svmParamSpace,
                           control = randSearch)

parallelStop()
tunedSvmPars
tunedSvmPars$x # our best model

# step 4 starting the model with the best hyperparameter results from random search
tunedSvm <- setHyperPars(makeLearner("classif.svm"),
                         par.vals = tunedSvmPars$x)

tunedSvmModel <- train(tunedSvm, spamTask)

# step 5 cross validation
outer <- makeResampleDesc("CV", iters = 3) # 3 fold cross validation
svmWrapper <- makeTuneWrapper("classif.svm", resampling = cvForTuning,
                              par.set = svmParamSpace,
                              control = randSearch)
parallelStartSocket(cpus = detectCores())
cvWithTuning <- resample(svmWrapper, spamTask, resampling = outer)
parallelStop()

cvWithTuning # mmce (misclassification error rate) is 0.19 - we are correctly classifying ~ 81% of cases.

# step 6 predict 2020 all nba with SVM 
pred3 <- predict(tunedSvmModel, newdata = nbaAllStarTest4)
getPredictionResponse(pred3)

SVMplayers <- nbaAllStarTest$Player
SVMplayers <- as.data.frame(SVMplayers)

SVMplayers$probability <- getPredictionResponse(pred3)

SVMplayers <- SVMplayers %>%
  arrange(desc(probability))
SVMplayers # top 15 only - looks to be 17 players are deserving of all-nba in 2020.
